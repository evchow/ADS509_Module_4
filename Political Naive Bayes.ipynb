{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "# see https://www.sqlite.org/lang_select.html for sqlite query syntax\n",
    "# SELECT (what you want to return) FROM (table)\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party\n",
    "                            FROM conventions\n",
    "                            ''')\n",
    "\n",
    "punctuation = set(punctuation) # a set of all punctuation\n",
    "whitespace = re.compile(r\"\\s+\") # regex to ID whitespace; not necessary because of hashtags\n",
    "sw = set(stopwords.words(\"english\")) # define the stopwords\n",
    "\n",
    "# the following is taken from previous Module assignments with minor adjustments\n",
    "# see https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "def remove_stop(tokens) :\n",
    "    # modify this function to remove stopwords\n",
    "    return[w for w in tokens if w not in sw]\n",
    "\n",
    "def remove_punctuation(text, punct_set=punctuation) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) :\n",
    "    # we'll have it return i, where i = tokens\n",
    "    return(i for i in whitespace.split(text))\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)    \n",
    "    return(tokens)\n",
    "\n",
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]\n",
    "\n",
    "for row in query_results:\n",
    "    text, party = row\n",
    "    prep = prepare(text, pipeline=my_pipeline)\n",
    "    # the following just transforms our tokenized list back into a string of words\n",
    "    speeches = \" \".join(prep)\n",
    "    convention_data.append([speeches, party])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['help reform broken criminal justice system joe end private prisons detention centers cash bail school prison pipeline heal soul nation joe biden end hate division trump created stop demonization immigrants coddling white nationalists racist dog whistling religious bigotry ugly attacks women',\n",
       "  'Democratic'],\n",
       " ['oh god truck sinking', 'Democratic'],\n",
       " ['six months president trump granted second chance signed first step act law real justice reform brought joy hope freedom thousands well deserving people hollered “hallelujah” faith justice mercy rewarded imagine getting hug loved ones think first step meant much many can’t wait we’re getting started nearly 22 years spent prison wasted god purpose plan life delayed denied destined time pray hear message inspired story compassion lead take action forgotten president donald trump forever grateful god bless god bless president trump god bless america thank',\n",
       "  'Republican'],\n",
       " ['unlike joe biden president trump didn’t choose i’m woman chose best person job four years ago president trump started movement unlike next four days hear millions hardworking everyday americans benefited leadership watched dnc last week probably noticed democrats spent lot time talking much despise president heard little actual policies policies would unthinkable decade ago policies like banning fossil fuels eliminating private health insurance taxpayer funded healthcare people come illegally defunding police',\n",
       "  'Republican'],\n",
       " ['there’s union perfect one brings us kitchen table every sunday night stir fry fry chicken spaghetti meatball family dinners',\n",
       "  'Democratic'],\n",
       " ['senator harris cares people there’s doubt', 'Democratic'],\n",
       " ['there’s something unique america don’t simply welcome new immigrants born immigrants immigration origin story unless family native american families come someplace else new americans see american stories life america always easy discrimination hardship poverty like doubt found inspiration come able muster faith america might build better life give children something',\n",
       "  'Democratic'],\n",
       " ['i’m resident council president south jamaica houses', 'Republican'],\n",
       " ['want acknowledge fact since march lives changed drastically invisible enemy covid19 swept across beautiful country impacted us deepest sympathy goes everyone lost loved one prayers ill suffering know many people anxious feel helpless want know you’re alone husband’s administration stop fighting effective treatment vaccine available everyone donald rest done take care everyone impacted terrible pandemic want extend gratitude healthcare professionals frontline workers teachers stepped difficult times despite risk families put country first husband grateful',\n",
       "  'Republican'],\n",
       " ['found love holds family together love makes us flexible resilient allows us become together though can’t protect us sorrows life gives us refuge home make broken family whole way make nation hole love understanding small acts kindness bravery unwavering faith show big ways small ones it’s many right loved ones complete strangers communities want tell us country hopelessly divided differences irreconcilable that’s i’ve seen last months we’re coming together holding onto we’re finding mercy grace moments might taken granted we’re seeing differences precious similarities infinite shown heart nation still beats kindness courage that’s soul america joe biden fighting dr',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    # define our dict\n",
    "    ret_dict = dict()\n",
    "    # below will tell it to respond with True if word is in the dict\n",
    "    for i in text.split():\n",
    "        if i in fw:\n",
    "            ret_dict[i]=True\n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the three assertion statements were broken up for more convenient troubleshooting\n",
    "assert(len(feature_words)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "Within the top 25 most informative features, only 2 of the features are informative in favor of Democrats. 23 of the 25 informative features tell us about the most used words for Republicans, which include many \"hot topic\" headline words commonly found in trending news articles such as \"china\", \"freedoms\", and \"enemy\". These words also align strongly with Republican ideals such as \"enforcement\", \"defense\", and \"amendment\". Meanwhile, Democratic hot topic words make sense as they align with some of the popular Democratic goals, such as urging for \"votes\" and \"climate\" change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "# same as above\n",
    "punctuation = set(punctuation) # a set of all punctuation\n",
    "whitespace = re.compile(r\"\\s+\") # regex to ID whitespace; not necessary because of hashtags\n",
    "sw = set(stopwords.words(\"english\")) # define the stopwords\n",
    "\n",
    "# the following is taken from previous Module assignments with minor adjustments\n",
    "# see https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "def remove_stop(tokens) :\n",
    "    # modify this function to remove stopwords\n",
    "    return[w for w in tokens if w not in sw]\n",
    "\n",
    "def remove_punctuation(text, punct_set=punctuation) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "def tokenize(text) :\n",
    "    # we'll have it return i, where i = tokens\n",
    "    return(i for i in whitespace.split(text))\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)    \n",
    "    return(tokens)\n",
    "\n",
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]\n",
    "\n",
    "for row in results:\n",
    "    candidate, party, tweet = row\n",
    "    decode = tweet.decode('utf-8')\n",
    "    prep = prepare(text=decode, pipeline=my_pipeline)\n",
    "    # the following just transforms our tokenized list back into a string of words\n",
    "    prepped_text = \" \".join(prep)\n",
    "    # we don't need the candidate for our classification later\n",
    "    # eliminating candidate here will remove the following error:\n",
    "    # ValueError: too many values to unpack (expected 2)\n",
    "    tweet_data.append([prepped_text, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['perrynelson thanks', 'Democratic'],\n",
       " ['great ag news today → restoring trade access china us beef producers incredible step forward httpstcorpl2dw3dec',\n",
       "  'Republican'],\n",
       " ['icymi bluevirginia jennifer discusses need replace politicians blame mentally ill acts gun violence httpstcoilynevbpqw',\n",
       "  'Democratic'],\n",
       " ['two days womensmarch realdonaldtrumps choice bring back globalgag rule reminds us must fight protectourcare',\n",
       "  'Democratic'],\n",
       " ['today 130pm president barack obama honor recipients 2010 medal freedom ceremony httpfbmevke2veh0',\n",
       "  'Democratic'],\n",
       " ['asked usda inspector general fong recent survey found scientists usda worry could face punishment researching issues relative climate change pollinator health antimicrobial resistance mepolitics watch➡️ httpstcoacisxw8s8a',\n",
       "  'Democratic'],\n",
       " ['happy presidents day realdonaldtrump presidentsday2018 httpstcol8xenamvap',\n",
       "  'Republican'],\n",
       " ['foxx votes require collection unpaid taxes federal employees httptinyurlcom3ajgnh6',\n",
       "  'Republican'],\n",
       " ['jaclopac realdonaldtrump people district also saying nunes follow twitter join fight oust nunes janzforcongress',\n",
       "  'Democratic'],\n",
       " ['ignoretrump follow great housedemocrats women instead repterrisewell repkarenbass repwilson repbonamici',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check\n",
    "random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: we’re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: let’s make even greater kag 🇺🇸 httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serve… httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot that’s 7000 nonmath majors room 😂 help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potus’s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastla’s 22 years eastside commitment amp saluted community leaders last night’s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    # see https://www.nltk.org/api/nltk.classify.html\n",
    "    estimate_set = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(estimate_set)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimate_set = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(estimate_set)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3806, 'Democratic': 608}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4662, 'Democratic': 926})})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "Similar to what was seen earlier in that most informative features belonging to those of Republican political parties, it appears that using those feature words to classify tweets from candidates has a higher accuracy in determining Republican candidates and a low accuracy in determing Democratic candidates. This has occurred because the classifer has overclassified a majority of the candidates as Republican using the feature words. This lines up consistently with our training set of feature words, as it predicted 50% accuracy. By overclassifying candidates as Republican, NB can essentially classify all candidates as Republicans and be correct half of the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
